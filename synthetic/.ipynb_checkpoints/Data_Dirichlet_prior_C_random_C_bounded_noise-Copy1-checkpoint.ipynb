{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../SRC')\n",
    "import CoDaS_PIOT_general_prior_C\n",
    "import plot as CoDaS_plot\n",
    "import Sinkhorn as CoDaS_Sinkhorn\n",
    "from matplotlib import cm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import pickle\n",
    "import itertools\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MCMC_sim(T_1, alpha, lam, std, shift, num_burn_in = 10000, num_sampling = 1000000, num_lag = 200):\n",
    "\n",
    "    # Hyperparameters\n",
    "    alphas = [alpha]\n",
    "    mean = 0.0\n",
    "    std = std\n",
    "\n",
    "    # Regularization for calculating W2\n",
    "    reg = 0.01\n",
    "\n",
    "    K_1, data_K_1, data_K_burn_in, acceptRatio_1 = \\\n",
    "    CoDaS_PIOT_general_prior_C.runs(T_1, alphas, lam, mean, std, shift, num_burn_in, num_sampling, num_lag)\n",
    "\n",
    "    print('Done...')\n",
    "    return data_K_1, data_K_burn_in\n",
    "\n",
    "def autocorr(x,lags,var):\n",
    "    n_vectors = len(x)\n",
    "    nr, nc = len(x[0]), len(x[0][0])\n",
    "    mean = x.mean(axis = 0)\n",
    "    xp = torch.stack([row-mean for row in x])\n",
    "    corr = np.array([np.correlate(xp[:,r,c],xp[:,r,c],'full') \\\n",
    "                     for r, c in itertools.product(range(nr), range(nc))])[:, n_vectors-1:]\n",
    "    div = np.array([n_vectors-i for i in range(len(lags))])\n",
    "    acorr = corr.sum(axis=0)[:len(lags)]/var/div\n",
    "\n",
    "    return acorr[:len(lags)]\n",
    "\n",
    "def plot_row_sum_corr(data):\n",
    "    nc = len(data[0][0])\n",
    "    row_sum = []\n",
    "\n",
    "    for i in range(len(data)):\n",
    "        row_sum.append(np.array(data[i].sum(axis=1)))\n",
    "\n",
    "    lags = range(1000)\n",
    "    var = np.var(row_sum, axis = 0).sum()\n",
    "    corr = CoDaS_plot.autocorr(row_sum, lags, var)\n",
    "\n",
    "    x = range(len(lags))\n",
    "    plus_1_div_exp = 1/np.exp(1)*np.ones(len(lags))\n",
    "    minus_1_div_exp = - plus_1_div_exp\n",
    "\n",
    "    plt.plot(lags, corr)\n",
    "    plt.plot(x, plus_1_div_exp, 'k--')\n",
    "    plt.plot(x, minus_1_div_exp, 'k--')\n",
    "    \n",
    "def plot_corr(data, lag = 1000):\n",
    "    \n",
    "    lags = range(lag)\n",
    "    var = torch.sum(torch.var(data, axis = 0))\n",
    "    corr = autocorr(data, lags, var)\n",
    "    \n",
    "    x = range(len(lags))\n",
    "    plus_1_div_exp = 1/np.exp(1)*np.ones(len(lags))\n",
    "    minus_1_div_exp = - plus_1_div_exp\n",
    "\n",
    "    plt.plot(lags, corr)\n",
    "    plt.plot(x, plus_1_div_exp, 'k--')\n",
    "    plt.plot(x, minus_1_div_exp, 'k--')\n",
    "    plt.xlabel('t')\n",
    "    plt.ylabel(\"R(t)\")\n",
    "        \n",
    "def plot_one_matrix_simplex(M):\n",
    "    CoDaS_plot.plot_points(np.array([t[0] for t in M]), 'r', 5)\n",
    "    CoDaS_plot.plot_points(np.array([t[1] for t in M]), 'g', 5)\n",
    "    CoDaS_plot.plot_points(np.array([t[2] for t in M]), 'b', 5)\n",
    "    \n",
    "def plot_samples(data, bw_method = 0.1):\n",
    "    nr = len(data[0])\n",
    "    nc = len(data[0][0])\n",
    "    x_i = [[] for _ in range(nr)]\n",
    "    df_all = pd.DataFrame()\n",
    "\n",
    "    colors = ['r', 'g', 'b']\n",
    "\n",
    "    for i in range(nr):\n",
    "        for j in range(nc):\n",
    "            x_i[i] = np.array([K[i][j].numpy() for K in data])\n",
    "\n",
    "            df = pd.DataFrame(x_i[i], columns = ['({},{})'.format(i, j)])\n",
    "\n",
    "            ax1 = df.plot.density(bw_method=bw_method)\n",
    "            ax1.set_xlim(0, 1)\n",
    "            ax1.set_ylim(bottom=0)\n",
    "            \n",
    "\n",
    "    \n",
    "def plot_samples_column(data, bw_method = 0.1):\n",
    "    nr = len(data[0])\n",
    "    nc = len(data[0][0])\n",
    "    x_i = [[] for _ in range(nr)]\n",
    "    df_all = pd.DataFrame()\n",
    "\n",
    "    colors = ['r', 'g', 'b']\n",
    "\n",
    "    for j in range(nc):\n",
    "        x_i = np.array([[K[i][j].numpy() for i in range(nr)] for K in data])\n",
    "\n",
    "        df = pd.DataFrame(x_i, columns = ['({},{})'.format(i,j) for i in range(nr) ])\n",
    "        ax1 = df.plot.density(bw_method=bw_method)\n",
    "        ax1.set_xlim(0, 1)\n",
    "\n",
    "        \n",
    "def running_average(data):\n",
    "    \n",
    "    nc = len(data[0][0])\n",
    "    x = []\n",
    "\n",
    "    for i in range(len(data)):\n",
    "        x.append(np.array(data[i].sum(axis=1)))\n",
    "\n",
    "    x = np.array(x)\n",
    "    nr = len(x)\n",
    "    nc = len(x[0])\n",
    "    ra = [x[0]]\n",
    "    for i in range(1, nr):\n",
    "        ra.append(ra[i-1] + x[i])\n",
    "    for i in range(1, nr):\n",
    "        ra[i] /= (i+1)\n",
    "    return ra\n",
    "\n",
    "def plot_row_sum_running_average(data):\n",
    "    ra = running_average(data)\n",
    "    df_ra = pd.DataFrame(ra)\n",
    "    ax = df_ra.plot()\n",
    "    ax.set_ylabel('Row sum')\n",
    "    ax.set_xlabel('# samples')\n",
    "    ax.set_ylim(bottom=0.1)\n",
    "\n",
    "\n",
    "def normalizeFactor(T):\n",
    "    m, n = len(T), len(T[0])\n",
    "    return np.exp( (1 + np.log(T).sum()) /m/n )\n",
    "\n",
    "def addNoise(T, noise):\n",
    "    T_p = T.clone()\n",
    "    T_p[0][0] += noise\n",
    "    a = normalizeFactor(T_p)\n",
    "    T_p = T_p / a\n",
    "    return T_p.clone(), a\n",
    "\n",
    "\n",
    "def plot_pdf_all_combined(data, C, bw_method = 0.05):\n",
    "    \n",
    "    data_all = []\n",
    "    for key in data.keys():\n",
    "        data_all += data[key]\n",
    "    nr = len(data[key][0])\n",
    "    nc = len(data[key][0][0])\n",
    "\n",
    "    colors = ['r', 'g', 'b']\n",
    "\n",
    "    for i in range(nr):\n",
    "        for j in range(nc):\n",
    "            x_i = np.array([K[i][j].numpy() for K in data_all])\n",
    "            df = pd.DataFrame(x_i, columns = ['({},{})'.format(i+1,j+1)])\n",
    "            ax1 = df.plot.density(bw_method=bw_method, color='k')\n",
    "            ylim = ax1.get_ylim()\n",
    "            ax1.vlines(C[i][j], ymin = 0, ymax = 100, linestyles = 'dashed')\n",
    "            ax1.set_ylim((0, ylim[1]))\n",
    "            ax1.set_xlim(left=0)\n",
    "\n",
    "def plot_pdf_all(data, bw_method = 0.05):\n",
    "    noises = [-0.01, -0.005, 0.0, 0.005, 0.01]\n",
    "    n_noise = len(data)\n",
    "    nr = len(data[str(noises[0])][0])\n",
    "    nc = len(data[str(noises[0])][0][0])\n",
    "    #x_i = [[] for _ in range(nr)]\n",
    "    df_all = pd.DataFrame()\n",
    "\n",
    "    colors = ['r', 'g', 'b']\n",
    "\n",
    "    for i in range(nr):\n",
    "        for j in range(nc):\n",
    "            df = pd.DataFrame()\n",
    "            for k in range(n_noise):\n",
    "                x_i = np.array([K[i][j].numpy() for K in data[str(noises[k])]])\n",
    "\n",
    "                df[noises[k]] = x_i\n",
    "            ax1 = df.plot.density(bw_method=bw_method, cmap = cm.get_cmap('RdBu_r'))\n",
    "            ax1.set_xlim(0, 0.5)\n",
    "            ax1.set_ylim(bottom=0)\n",
    "\n",
    "    \n",
    "def plot_pdf_CR(data, bw_method = 0.05):\n",
    "    noises = [-0.01, -0.005, 0.0, 0.005, 0.01]\n",
    "    n_noise = len(data)\n",
    "    nr = len(data[str(noises[0])][0])\n",
    "    nc = len(data[str(noises[0])][0][0])\n",
    "    #x_i = [[] for _ in range(nr)]\n",
    "    df_all = pd.DataFrame()\n",
    "\n",
    "    color = ['b', 'b', 'g', 'g', 'y', 'y', 'orange', 'orange', 'r', 'r']\n",
    "    linestyles = ('-', '--')\n",
    "    styles = ['b-', 'b--', 'c-', 'c--', 'k-', 'k--', 'm-', 'm--', 'r-', 'r--']\n",
    "\n",
    "\n",
    "    # x_00+x_11 v.s. x_01+x_10\n",
    "    df = pd.DataFrame()\n",
    "    for k in range(n_noise):\n",
    "        x_1 = np.array([K[0][0].numpy()+K[1][1].numpy() for K in data[str(noises[k])]])\n",
    "        df[(noises[k],\"$C_{11}+C_{22}$\")] = x_1\n",
    "        x_2 = np.array([K[1][0].numpy()+K[0][1].numpy() for K in data[str(noises[k])]])\n",
    "        df[(noises[k],\"$C_{21}+C_{12}$\")] = x_2\n",
    "\n",
    "    ax1 = df.plot.density(bw_method=bw_method, style=styles, legend=False)\n",
    "    ax1.set_xlim(0, 0.6)\n",
    "    ax1.set_ylim(bottom=0)\n",
    "\n",
    "    # x_01+x_02 v.s. x_11+x_12\n",
    "    df = pd.DataFrame()\n",
    "    for k in range(n_noise):\n",
    "        x_1 = np.array([K[0][1].numpy()+K[1][2].numpy() for K in data[str(noises[k])]])\n",
    "        df[(noises[k],\"$C_{12}+C_{23}$\")] = x_1\n",
    "        x_2 = np.array([K[0][2].numpy()+K[1][1].numpy() for K in data[str(noises[k])]])\n",
    "        df[(noises[k],\"$C_{13}+C_{22}$\")] = x_2\n",
    "\n",
    "    ax1 = df.plot.density(bw_method=bw_method, style=styles, legend=False)\n",
    "    ax1.set_xlim(0, 0.6)\n",
    "    ax1.set_ylim(bottom=0)\n",
    "\n",
    "    \n",
    "def compute_CR(data, bw_method = 0.05):\n",
    "    noises = [-0.01, -0.005, 0.0, 0.005, 0.01]\n",
    "    n_noise = len(data)\n",
    "    nr = len(data[str(noises[0])][0])\n",
    "    nc = len(data[str(noises[0])][0][0])\n",
    "    df_all = pd.DataFrame()\n",
    "\n",
    "    colors = ['r', 'g', 'b']\n",
    "\n",
    "\n",
    "    # x_00+x_01 - x_01-x_11\n",
    "    df = pd.DataFrame()\n",
    "    for k in range(n_noise):\n",
    "        x_1 = np.array([K[0][1].numpy()+K[1][0].numpy()-K[0][0].numpy()-K[1][1].numpy() for K in data[str(noises[k])]])\n",
    "        df[(noises[k])] = x_1\n",
    "    df.hist(bins=50)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2096, 0.1130, 0.0313],\n",
       "        [0.0122, 0.0294, 0.2243],\n",
       "        [0.0688, 0.1480, 0.1634]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C = torch.rand((3,3))\n",
    "C = C / C.sum()\n",
    "C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0995, 0.1098, 0.1240],\n",
       "        [0.1179, 0.1161, 0.0994],\n",
       "        [0.1160, 0.1074, 0.1100]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K = np.exp(-C)\n",
    "stopThr = 1e-7\n",
    "numItermax = 1e6\n",
    "r, c = torch.ones(len(K))/len(K), torch.ones(len(K[0]))/len(K[0])\n",
    "T = CoDaS_Sinkhorn.sinkhorn_torch(mat=K,\n",
    "                                row_sum = r, \n",
    "                                col_sum = c, \n",
    "                                epsilon=stopThr, \n",
    "                                max_iter=numItermax)\n",
    "T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('T_for_uniform_noise.pkl', 'wb') as handle:\n",
    "    pickle.dump(T, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.01, -0.005, 0.0, 0.005, 0.01]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noises = [-0.01, -0.005, 0.0, 0.005, 0.01]\n",
    "noises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def sim(T):\n",
    "    std = 0.0\n",
    "    power_k = 3\n",
    "    shift = 0.02\n",
    "    alpha = 1.0\n",
    "    lam = 1.0\n",
    "    num_burn_in = 10000\n",
    "    num_lag = 100\n",
    "    num_sampling = num_lag*100000\n",
    "\n",
    "\n",
    "    data_C, data_C_burn_in = MCMC_sim(T, alpha, lam, std, shift, num_burn_in, num_sampling, num_lag)\n",
    "    return data_C, data_C_burn_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.01\n",
      "tensor(0.1224)\n",
      "tensor([[0.7312, 0.8973, 1.0128],\n",
      "        [0.9628, 0.9485, 0.8118],\n",
      "        [0.9474, 0.8773, 0.8984]])\n",
      "tensor([[ 0.3130,  0.1083, -0.0127],\n",
      "        [ 0.0379,  0.0529,  0.2085],\n",
      "        [ 0.0540,  0.1310,  0.1071]])\n",
      "-0.005\n",
      "tensor(0.1232)\n",
      "tensor([[0.7674, 0.8919, 1.0067],\n",
      "        [0.9570, 0.9428, 0.8069],\n",
      "        [0.9417, 0.8720, 0.8930]])\n",
      "tensor([[ 0.2647,  0.1144, -0.0067],\n",
      "        [ 0.0440,  0.0589,  0.2145],\n",
      "        [ 0.0601,  0.1370,  0.1131]])\n",
      "0.0\n",
      "tensor(0.1239)\n",
      "tensor([[0.8034, 0.8868, 1.0010],\n",
      "        [0.9515, 0.9374, 0.8023],\n",
      "        [0.9363, 0.8670, 0.8879]])\n",
      "tensor([[ 0.2189,  0.1201, -0.0010],\n",
      "        [ 0.0497,  0.0647,  0.2202],\n",
      "        [ 0.0658,  0.1427,  0.1189]])\n",
      "0.005\n",
      "tensor(0.1245)\n",
      "tensor([[0.8392, 0.8820, 0.9955],\n",
      "        [0.9463, 0.9323, 0.7980],\n",
      "        [0.9312, 0.8623, 0.8831]])\n",
      "tensor([[0.1753, 0.1255, 0.0045],\n",
      "        [0.0551, 0.0701, 0.2257],\n",
      "        [0.0713, 0.1482, 0.1243]])\n",
      "0.01\n",
      "tensor(0.1252)\n",
      "tensor([[0.8748, 0.8775, 0.9904],\n",
      "        [0.9414, 0.9275, 0.7938],\n",
      "        [0.9264, 0.8578, 0.8785]])\n",
      "tensor([[0.1338, 0.1307, 0.0097],\n",
      "        [0.0603, 0.0753, 0.2309],\n",
      "        [0.0765, 0.1534, 0.1295]])\n"
     ]
    }
   ],
   "source": [
    "for noise in noises:\n",
    "    T_p, a = addNoise(T, noise)\n",
    "    print(noise)\n",
    "    print(a)\n",
    "    print(T_p)\n",
    "    print(-np.log(T_p))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Burn in steps:\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Parameter vector 'a' must be one dimensional, but a.shape = (1, 9).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-2e408f2de028>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mnoise\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnoises\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mT_p\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maddNoise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoise\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mdata_C\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_C_burn_in\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mT_p\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mdata_C_all\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoise\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_C\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mdata_C_burn_in_all\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoise\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_C_burn_in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-7d3e0703dbc2>\u001b[0m in \u001b[0;36msim\u001b[0;34m(T)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mdata_C\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_C_burn_in\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMCMC_sim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshift\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_burn_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_sampling\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_lag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata_C\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_C_burn_in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-1a9450dfd42a>\u001b[0m in \u001b[0;36mMCMC_sim\u001b[0;34m(T_1, alpha, lam, std, shift, num_burn_in, num_sampling, num_lag)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mK_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_K_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_K_burn_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macceptRatio_1\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mCoDaS_PIOT_general_prior_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mruns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mT_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malphas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshift\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_burn_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_sampling\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_lag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Done...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/GitHub/Discrete_PIOT/SRC/CoDaS_PIOT_general_prior_C.py\u001b[0m in \u001b[0;36mruns\u001b[0;34m(T, alphas, lam, mean, std, shift, num_burn_in, num_sampling, num_lag, C)\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Burn in steps:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0mburnInFlag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m     \u001b[0mC_burn_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprob_burn_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_C_burn_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macceptRatio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmonteCarlo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malphas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshift\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_burn_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mburnInFlag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_lag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Burn in acceptance Ratio: %1.2f\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0macceptRatio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/GitHub/Discrete_PIOT/SRC/CoDaS_PIOT_general_prior_C.py\u001b[0m in \u001b[0;36mmonteCarlo\u001b[0;34m(T, alphas, lam, mean, std, shift, max_iter, burnInFlag, num_lag, C_old, prob_old)\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mprob_old\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0mprob_old\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m         \u001b[0mprob_old\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprob_old\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdirichlet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpdf\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mC_old\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m \u001b[0mC_old\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malphas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[0;31m# print('Prob. old: %1.2e' % prob_old)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/pyOT/lib/python3.8/site-packages/scipy/stats/_multivariate.py\u001b[0m in \u001b[0;36mpdf\u001b[0;34m(self, x, alpha)\u001b[0m\n\u001b[1;32m   1480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1481\u001b[0m         \"\"\"\n\u001b[0;32m-> 1482\u001b[0;31m         \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_dirichlet_check_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1483\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_dirichlet_check_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/pyOT/lib/python3.8/site-packages/scipy/stats/_multivariate.py\u001b[0m in \u001b[0;36m_dirichlet_check_parameters\u001b[0;34m(alpha)\u001b[0m\n\u001b[1;32m   1241\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"All parameters must be greater than 0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1242\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1243\u001b[0;31m         raise ValueError(\"Parameter vector 'a' must be one dimensional, \"\n\u001b[0m\u001b[1;32m   1244\u001b[0m                          \"but a.shape = %s.\" % (alpha.shape, ))\n\u001b[1;32m   1245\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Parameter vector 'a' must be one dimensional, but a.shape = (1, 9)."
     ]
    }
   ],
   "source": [
    "data_C_all = {}\n",
    "data_C_burn_in_all = {}\n",
    "\n",
    "for noise in noises:\n",
    "    T_p, _ = addNoise(T, noise)\n",
    "    data_C, data_C_burn_in = sim(T_p.clone())\n",
    "    data_C_all[str(noise)] = data_C\n",
    "    data_C_burn_in_all[str(noise)] = data_C_burn_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data_C_noise.pkl', 'wb') as handle:\n",
    "    pickle.dump(data_C_all, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open('data_C_burn_in_noise.pkl', 'wb') as handle:\n",
    "    pickle.dump(data_C_burn_in_all, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in data_C_burn_in_all.keys():\n",
    "    plot_corr(torch.stack(data_C_burn_in_all[key]), lag = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.rcParams.update({'font.size': 20})\n",
    "plot_pdf_CR(data_C_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in data_C_all.keys():\n",
    "    plot_row_sum_running_average(data_C_all[key])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
