{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append('../SRC')\n",
    "from PIOT_imports import *\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from torch.distributions import Dirichlet\n",
    "from numpy.random import uniform\n",
    "import random\n",
    "from PIOT_PSGD import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_index(t1, t2):\n",
    "\n",
    "    indices = []\n",
    "\n",
    "    for p in t1[\"Player\"]:\n",
    "        idx = t2[t2[\"Player\"]==p].index.tolist()\n",
    "        val = idx[0] if len(idx) > 0 else -1\n",
    "        indices.append(val)\n",
    "    return indices\n",
    "\n",
    "def build_T_pre(T, idx_cost_mat, marginal_exclusion, team1, team_composite, cols):\n",
    "    # T_pre shape = (# of players, # of feaures)\n",
    "    \n",
    "    T_cols = {}\n",
    "    for t in T:\n",
    "        T_cols[t] = torch.tensor( T[t][cols].to_numpy())\n",
    "\n",
    "    T_pre = torch.zeros(size=(len(idx_cost_mat), len(T_cols[team1][1]) ))\n",
    "    for idx, item in enumerate(idx_cost_mat):\n",
    "        team = item[1]\n",
    "        row = item[2]\n",
    "        # rescale T matrix\n",
    "        #ratio = len(T_cols[team])/len(idx_cost_mat)\n",
    "        ratio = 1.\n",
    "        T_pre[idx] = T_cols[team][row]*ratio\n",
    "\n",
    "    return T_pre\n",
    "\n",
    "def find_pre_team(player_transfer, year, cur_team):\n",
    "    '''\n",
    "    input:\n",
    "        player_transfer (dict): {year, {team: [(player, team player transferred from)]}}\n",
    "        year (int): season ending year\n",
    "        cur_team (str): team of current season\n",
    "    output:\n",
    "        pre_team (str): {team of current season, [team from precious season]}\n",
    "    '''\n",
    "    pre_team = []\n",
    "\n",
    "    if cur_team not in player_transfer[year]:\n",
    "        print(\"WARNING: current team not in player transfer list.\")\n",
    "    else:\n",
    "        for p, t in player_transfer[year][cur_team]:\n",
    "            if t is not None:\n",
    "                pre_team.append((p, t))\n",
    "\n",
    "    return pre_team\n",
    "\n",
    "def find_pre_marginals(player_transfer, team1, year):\n",
    "\n",
    "    load_folder = '../NBA/data/team_data/'\n",
    "    y_str_minus_1 = str(year-1)\n",
    "    y_str = str(year)\n",
    "    team_composite = [team1]\n",
    "\n",
    "    pre_team = find_pre_team(player_transfer, year, team1)\n",
    "\n",
    "    with open(load_folder + '{}_{}.pkl'.format(team1, y_str), 'rb') as f:\n",
    "        data_cur_season = pickle.load(f).reset_index()\n",
    "\n",
    "    data_pre_season = {}\n",
    "    with open(load_folder + '{}_{}.pkl'.format(team1, y_str_minus_1), 'rb') as f:\n",
    "        data_pre_season[team1] = pickle.load(f).reset_index()\n",
    "\n",
    "    for p, t in pre_team:\n",
    "        team_composite.append(t)\n",
    "        with open(load_folder + '{}_{}.pkl'.format(t, y_str_minus_1), 'rb') as f:\n",
    "            data_tmp = pickle.load(f).reset_index()\n",
    "        data_pre_season[t] = data_tmp\n",
    "\n",
    "    players_cur = pd.DataFrame(data_cur_season[\"Player\"])\n",
    "    players_pre = pd.DataFrame(data_pre_season[team1][\"Player\"])\n",
    "\n",
    "    for t in team_composite:\n",
    "        players_cur[t] = find_index(players_cur, data_pre_season[t])\n",
    "\n",
    "    idx_cost_mat = []\n",
    "    marginal_exclusion = []\n",
    "    for idx in range(len(players_cur)):\n",
    "        tf = False\n",
    "        for t in team_composite:\n",
    "            if players_cur.iloc[idx][t] != -1:\n",
    "                tf = True\n",
    "                break\n",
    "        if tf:\n",
    "            idx_cost_mat.append((idx, t, players_cur.iloc[idx][t])) \n",
    "        else:\n",
    "            marginal_exclusion.append(idx)\n",
    "            \n",
    "    # Load T data from previous season\n",
    "    T_data_folder = '../NBA/data/team_data/' \n",
    "    T_data = {}\n",
    "    for t in team_composite:\n",
    "        with open(T_data_folder + '{}_{}.pkl'.format(t, y_str_minus_1), 'rb') as f:\n",
    "            T_tmp = pickle.load(f)\n",
    "        T_data[t] = T_tmp\n",
    "    \n",
    "    cols = ['PTS','ORB','DRB','AST','STL']\n",
    "    T_pre = build_T_pre(T_data, idx_cost_mat, marginal_exclusion, team1, team_composite, cols = ['PTS','ORB','DRB','AST','STL'])\n",
    "\n",
    "    \n",
    "#     marg_data = data_cur_season[cols] \n",
    "#     marg = data_to_mat(marg_data.drop(index = marginal_exclusion), cols = cols)\n",
    "#     marg = marg / marg.sum(axis=0)\n",
    "#     marg_r= marg.sum(axis=1)\n",
    "#     marg_c= marg.sum(axis=0)\n",
    "    \n",
    "    return T_pre, marginal_exclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def row_iter(K, b, row_sum):\n",
    "    return row_sum / torch.matmul(K, torch.transpose(b, 0, -1))\n",
    "\n",
    "def col_iter(K, a, col_sum):\n",
    "    return col_sum / torch.matmul(torch.transpose(K, 0, 1), torch.transpose(a, 0, -1))\n",
    "\n",
    "def sinkhorn_torch_base(K,\n",
    "                        row_sum,\n",
    "                        col_sum,\n",
    "                        num_iter\n",
    "                        ):\n",
    "    '''\n",
    "    Sinkhorn scaling base\n",
    "    Parameters\n",
    "    ----------\n",
    "    mat     : muted torch 2-tensor of shape(n,m)\n",
    "    row_sum : immuted torch 1-tensor of size n\n",
    "    col_sum : immuted torch 1-tensor of size m\n",
    "    epsilon : tolerance of 1-norm on column-sums with rows normalized\n",
    "    max_iter: maximal iteration steps (multiples of 10)\n",
    "    Return\n",
    "    ------\n",
    "    Sinkhorn scaled matrix \n",
    "    '''\n",
    "    \n",
    "    a = torch.ones(len(row_sum))\n",
    "    b = torch.ones(len(col_sum))\n",
    "\n",
    "    while num_iter:\n",
    "        a = row_iter(K, b, row_sum)\n",
    "        b = col_iter(K, a, col_sum)\n",
    "\n",
    "        num_iter -= 1\n",
    "\n",
    "    return torch.matmul(torch.matmul(torch.diag(a), K.clone()), torch.diag(b))\n",
    "\n",
    "\n",
    "def sinkhorn_loss(K, r, c, L, nr, nc, q = None):\n",
    "    if q is None:\n",
    "        q = torch.ones(nr)\n",
    "    T = sinkhorn_torch_base(K.clone(),\n",
    "                   row_sum=r,\n",
    "                   col_sum=c,\n",
    "                   num_iter = L)\n",
    "    return (-torch.log(K)*T).sum() \\\n",
    "            +(T*(torch.log(T)-torch.ones((nr,nc)))).sum()\\\n",
    "            +0.1*(r*(torch.log(r)-torch.ones(nr))).sum()\n",
    "            #+0.5*(r.sum()-torch.tensor([nc], dtype=torch.float))**2\n",
    "            #\n",
    "        \n",
    "def sinkhorn_loss_cross_entropy(K, r, c, L, nr, nc, mu):\n",
    "    T = sinkhorn_torch_base(K.clone(),\n",
    "                   row_sum=r,\n",
    "                   col_sum=c,\n",
    "                   num_iter = L)\n",
    "    return (-torch.log(K)*T).sum() \\\n",
    "            +(T*(torch.log(T)-torch.ones((nr,nc)))).sum()\\\n",
    "            +(mu*(torch.log(r)-torch.ones(nr))).sum()\n",
    "\n",
    "            \n",
    "             \n",
    "\n",
    "\n",
    "def init(nr, nc, mean, std, num_matrices):\n",
    "    matrices = []\n",
    "\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    #torch.manual_seed(42)\n",
    "    r = torch.ones(nr, requires_grad=True, dtype=torch.float, device=device)\n",
    "    #r = torch.normal(size = (nr,), mean = 1.0, std = 0.01, requires_grad=True, dtype=torch.float, device=device)\n",
    "    c = torch.ones(nc, requires_grad=False, dtype=torch.float, device=device)\n",
    "\n",
    "    for _ in range(num_matrices):\n",
    "        # Dirichlet ---\n",
    "        Dir = Dirichlet(0.5*torch.ones((nr, nc)))\n",
    "        new_mat = Dir.sample()\n",
    "        \n",
    "        # Gaussian ---\n",
    "        #new_mat = torch.normal(mean = mean, std = std, size = (nr, nc))\n",
    "        #new_mat = torch.normal(mean = mean*torch.ones(nr), std = std)\n",
    "        #while new_mat.min() < 0.:\n",
    "        #    new_mat = torch.normal(mean = mean, std = std, size = (nr, nc))     \n",
    "        \n",
    "        # Diagonal ---\n",
    "        #new_mat = torch.diag(new_mat)\n",
    "        #adds = torch.ones((nr, nc))*1e-15\n",
    "        #new_mat += adds\n",
    "\n",
    "        matrices.append(new_mat)\n",
    "\n",
    "    print(r)\n",
    "    print(c)\n",
    "    print(matrices[0])\n",
    "    print('\\n')\n",
    "    \n",
    "    return r, c, matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NBA matrix, random initial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_transfer_path = \"../NBA/data/player_transfer/player_transfer_all_years.pkl\"\n",
    "with open(player_transfer_path, 'rb') as f:\n",
    "    player_transfer = pickle.load(f)\n",
    "\n",
    "team = \"CLE\"\n",
    "year = 2019\n",
    "num_sub_samples = 10000\n",
    "\n",
    "matrices, T_truth = load_pre_matrices(team, year, player_transfer, num_sub_samples = num_sub_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PTS</th>\n",
       "      <th>ORB</th>\n",
       "      <th>DRB</th>\n",
       "      <th>AST</th>\n",
       "      <th>STL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>16.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>12.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2.1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>9.4</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510</th>\n",
       "      <td>6.5</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2.4</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519</th>\n",
       "      <td>13.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>4.1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590</th>\n",
       "      <td>16.7</td>\n",
       "      <td>0.7</td>\n",
       "      <td>2.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>645</th>\n",
       "      <td>10.9</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>704</th>\n",
       "      <td>7.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      PTS  ORB  DRB  AST  STL\n",
       "138  16.8  1.0  2.3  2.4  0.7\n",
       "306  12.2  0.4  2.1  2.0  0.8\n",
       "498   9.4  2.5  5.7  3.2  1.5\n",
       "510   6.5  0.8  2.4  1.1  0.7\n",
       "519  13.0  0.6  4.1  2.6  0.8\n",
       "590  16.7  0.7  2.2  3.0  0.5\n",
       "645  10.9  4.0  6.2  2.0  0.7\n",
       "704   7.8  1.8  3.6  0.9  0.2"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pkl_file_g = open('../NBA/data/team_data/CLE_2019.pkl', 'rb')\n",
    "NBA_data_g = pickle.load(pkl_file_g)\n",
    "\n",
    "features = ['PTS', 'ORB', 'DRB', 'AST', 'STL']\n",
    "data = NBA_data_g[features]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3563, 0.1081, 0.1392, 0.4400, 0.1944],\n",
       "        [0.2113, 0.3514, 0.2658, 0.1867, 0.3889],\n",
       "        [0.1941, 0.1757, 0.2152, 0.2000, 0.2222],\n",
       "        [0.0958, 0.0405, 0.1076, 0.0933, 0.1111],\n",
       "        [0.1425, 0.3243, 0.2722, 0.0800, 0.0833]])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T_pre, marginal_exclusion = find_pre_marginals(player_transfer, team1, year)\n",
    "T_pre_norm = T_pre/T_pre.sum(axis=0)\n",
    "T_pre_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.2381, 1.4040, 1.0072, 0.4484, 0.9023])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# row marginals of composed T from previous year\n",
    "T_pre_norm.sum(axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2968, 0.1124, 0.1111, 0.2124, 0.1591],\n",
       "        [0.1661, 0.2809, 0.2754, 0.2832, 0.3409],\n",
       "        [0.1148, 0.0899, 0.1159, 0.0973, 0.1591],\n",
       "        [0.2297, 0.0674, 0.1981, 0.2301, 0.1818],\n",
       "        [0.1926, 0.4494, 0.2995, 0.1770, 0.1591]], dtype=torch.float64)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T_cur = torch.tensor(data.reset_index().drop(marginal_exclusion)[features].to_numpy())\n",
    "T_cur_norm = T_cur/T_cur.sum(axis=0)\n",
    "T_cur_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.8918, 1.3464, 0.5771, 0.9071, 1.2776], dtype=torch.float64)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# row marginals of ground truth T\n",
    "T_cur_norm.sum(axis=1)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularization, w/ projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.], requires_grad=True)\n",
      "tensor([1., 1., 1., 1., 1.], requires_grad=True)\n",
      "tensor([[0.2331, 0.1617, 0.1321, 0.2296, 0.1781],\n",
      "        [0.0246, 0.0934, 0.0448, 0.0173, 0.0633],\n",
      "        [0.0060, 0.0206, 0.0075, 0.0050, 0.0066],\n",
      "        [0.0505, 0.0548, 0.0714, 0.0545, 0.0782],\n",
      "        [0.0022, 0.0128, 0.0053, 0.0014, 0.0017]])\n",
      "\n",
      "\n",
      "Epoch 0\n",
      "Loss: 83267.1498496458\n",
      "r: tensor([0.8386, 0.8391, 1.3354, 1.0182, 0.9688], requires_grad=True)\n",
      "5.0\n",
      "c: tensor([1., 1., 1., 1., 1.], requires_grad=True)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nr, nc = len(matrices[0]), len(matrices[0][0])\n",
    "\n",
    "L = 100\n",
    "lr = 0.01\n",
    "num_epoch = 2\n",
    "num_epoch_outer = 10\n",
    "\n",
    "#device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device = 'cpu'\n",
    "vec = torch.ones(nr)\n",
    "vec = vec/vec.sum()*nc\n",
    "r = torch.tensor(vec, requires_grad=True, dtype=torch.float, device=device)\n",
    "c = torch.ones(nc, requires_grad=True, dtype=torch.float, device=device)\n",
    "\n",
    "data_loss = []\n",
    "data_r = []\n",
    "data_c = []\n",
    "\n",
    "print(r)\n",
    "print(c)\n",
    "print(matrices[0])\n",
    "print('\\n')\n",
    "\n",
    "for i in range(num_epoch_outer):\n",
    "    for marginal in [r, c]:\n",
    "\n",
    "            optimizer = torch.optim.RMSprop([marginal], lr=lr)\n",
    "\n",
    "            for epoch in range(num_epoch):\n",
    "                running_loss = 0\n",
    "                for i in range(len(matrices)):\n",
    "                    loss = sinkhorn_loss(matrices[i].clone(), r, c, L, nr, nc )\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    with torch.no_grad():\n",
    "                        for param in [r, c]:\n",
    "                            param[:] = param.clamp(1e-15, 10)\n",
    "                            param[:] = param / param.sum() * nc\n",
    "                            \n",
    "\n",
    "                    running_loss += loss.item()\n",
    "\n",
    "                data_loss.append(running_loss)\n",
    "                data_r.append(r.cpu().detach().clone().numpy())\n",
    "                data_c.append(c.cpu().detach().clone().numpy())\n",
    "\n",
    "                print('Epoch {}'.format(epoch))\n",
    "                print('Loss: {}'.format(running_loss))\n",
    "                print('r: {}'.format(r))\n",
    "                print(r.sum().detach().numpy())\n",
    "                print('c: {}'.format(c))\n",
    "                print('\\n')\n",
    "    \n",
    "print(data_r[-1])\n",
    "print(data_r[-1].sum())\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize = (10, 5))\n",
    "\n",
    "ax[0].plot(data_loss)\n",
    "ax[0].set_title('Loss')\n",
    "ax[1].plot(data_r)\n",
    "ax[1].set_title('Marginal')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = [0.6254, 0.8030, 0.6242, 0.6430, 0.5401, 0.4455, 0.7436, 0.5752]\n",
    "\n",
    "r_pred = pd.DataFrame([np.round(pred, 7), mu])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.6254</td>\n",
       "      <td>0.803</td>\n",
       "      <td>0.6242</td>\n",
       "      <td>0.643</td>\n",
       "      <td>0.5401</td>\n",
       "      <td>0.4455</td>\n",
       "      <td>0.7436</td>\n",
       "      <td>0.5752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23.2000</td>\n",
       "      <td>17.500</td>\n",
       "      <td>22.3000</td>\n",
       "      <td>11.500</td>\n",
       "      <td>21.1000</td>\n",
       "      <td>23.1000</td>\n",
       "      <td>23.8000</td>\n",
       "      <td>14.3000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0       1        2       3        4        5        6        7\n",
       "0   0.6254   0.803   0.6242   0.643   0.5401   0.4455   0.7436   0.5752\n",
       "1  23.2000  17.500  22.3000  11.500  21.1000  23.1000  23.8000  14.3000"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.975"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.abs(np.array(pred) - mu.to_numpy()).sum()/8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
